
### to_datetime && set_index && drop

#### to_datetime
将字符串转成时间序列：to_datetime
设置索引：set_index
```python
dic = {
    'time':['2020-06-01','2020-06-02','2020-06-04'],
    'salary':[10000,11000,11100]
}
df = pd.DataFrame(data=dic)

# to_datetime方法
df['time'] = pd.to_datetime(df['time'])
df.dtypes
time      datetime64[ns]
salary             int64
dtype: object
```

#### set_index
```
#将time作为行索引
df.set_index(df['time'])
	time	salary
time		
2020-06-01	2020-06-01	10000
2020-06-02	2020-06-02	11000
2020-06-04	2020-06-04	11100

# 将它作用到原数据上：inplace=True
df.set_index(df['time'],inplace=True)
df
	time	salary
time		
2020-06-01	2020-06-01	10000
2020-06-02	2020-06-02	11000
2020-06-04	2020-06-04	11100
```
关于index的一点补充:
set_index中第一个参数为字段名，如果直接写的字段名如：time,此时drop参数才有效，默认行为是drop=True,此时指定time为索引，即删除了time这一列，将它用来作为索引。而如果是像上面那样使用的
df['time']这样指定，则drop失去作用。
```python
#
df.set_index('time',inplace=True,drop=False)
df
	time	salary
time		
2020-06-01	2020-06-01	10000
2020-06-02	2020-06-02	11000
2020-06-04	2020-06-04	11100
```
#### drop
手动删除列：注意在drop方法中 axis=1时表示列，axis=0表示行
```python
df.drop(labels='time',axis=1)
```


## 分类问题

垃圾邮件检测，图像分类（人脸识别）

> 逻辑回归
用于解决分类问题的一种模型。根据数据特征或属性,计算其归属于某一类别
的概率P(x),根据概率数值判断其所属类别。主要应用场景:二分类问题。

sigmoid函数

$$p(x) =\frac{1}{1+e^{-x}}$$

$$p(x) = \frac{1}{1+e^{g(x)}}$$
其中的g(x) 被称为decision boundary 决策边界

$$g(x)=\theta+\theta_1x_1+\theta_2x_2+...$$


### 逻辑回归实现二分类

```python
from sklearn.linear_model import LogisticRegression
lr_model = LogisticRegression()
lr_model.fit(x,y)

# 边界函数系统
theta1, theta2 = lr_model.coef_[0][0],lr_model.coef_[0][1]
theta0 = lr_model.intercept_[0]

# 对新数据做预测
predictions = lr_model.predict(x_new) # x_new 为输入参数？？

#计算准确率

from sklearn.metrics import accuracy_score

y_predict = lr_model.predict(x)
accuracy = accuracy_score(y, y_predict)

# 画图看决策边界效果，可视化
plt.plot(x1, x2_boundary)
passed = plt.scatter(x1[mask], x2[mask])
failed = plt.scatter(x[~mask], x2[~mask], marker='^')
```

### K-means
均值聚类  无监督

以空间中k个点为中心，对最靠近它们的点归类

### KNN
近邻分类  有监督（已标记好的数据,必须告诉它分几类）


### meanShift
均值漂移， 基于密度梯度上升方向聚类  使用向量



### MLP


max-pooling : 最大法池化
avg-pooling: 平均池化