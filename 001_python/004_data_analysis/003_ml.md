
### to_datetime && set_index && drop

#### to_datetime
将字符串转成时间序列：to_datetime
设置索引：set_index
```python
dic = {
    'time':['2020-06-01','2020-06-02','2020-06-04'],
    'salary':[10000,11000,11100]
}
df = pd.DataFrame(data=dic)

# to_datetime方法
df['time'] = pd.to_datetime(df['time'])
df.dtypes
time      datetime64[ns]
salary             int64
dtype: object
```

#### set_index
```
#将time作为行索引
df.set_index(df['time'])
	time	salary
time		
2020-06-01	2020-06-01	10000
2020-06-02	2020-06-02	11000
2020-06-04	2020-06-04	11100

# 将它作用到原数据上：inplace=True
df.set_index(df['time'],inplace=True)
df
	time	salary
time		
2020-06-01	2020-06-01	10000
2020-06-02	2020-06-02	11000
2020-06-04	2020-06-04	11100
```
关于index的一点补充:
set_index中第一个参数为字段名，如果直接写的字段名如：time,此时drop参数才有效，默认行为是drop=True,此时指定time为索引，即删除了time这一列，将它用来作为索引。而如果是像上面那样使用的
df['time']这样指定，则drop失去作用。
```python
#
df.set_index('time',inplace=True,drop=False)
df
	time	salary
time		
2020-06-01	2020-06-01	10000
2020-06-02	2020-06-02	11000
2020-06-04	2020-06-04	11100
```
#### drop
手动删除列：注意在drop方法中 axis=1时表示列，axis=0表示行
```python
df.drop(labels='time',axis=1)
```


## 分类问题

垃圾邮件检测，图像分类（人脸识别）

> 逻辑回归
用于解决分类问题的一种模型。根据数据特征或属性,计算其归属于某一类别
的概率P(x),根据概率数值判断其所属类别。主要应用场景:二分类问题。

sigmoid函数

$$p(x) =\frac{1}{1+e^{-x}}$$

$$p(x) = \frac{1}{1+e^{g(x)}}$$
其中的g(x) 被称为decision boundary 决策边界

$$g(x)=\theta+\theta_1x_1+\theta_2x_2+...$$


### 逻辑回归实现二分类

```python
from sklearn.linear_model import LogisticRegression
lr_model = LogisticRegression()
lr_model.fit(x,y)

# 边界函数系统
theta1, theta2 = lr_model.coef_[0][0],lr_model.coef_[0][1]
theta0 = lr_model.intercept_[0]

# 对新数据做预测
predictions = lr_model.predict(x_new) # x_new 为输入参数？？

#计算准确率

from sklearn.metrics import accuracy_score

y_predict = lr_model.predict(x)
accuracy = accuracy_score(y, y_predict)

# 画图看决策边界效果，可视化
plt.plot(x1, x2_boundary)
passed = plt.scatter(x1[mask], x2[mask])
failed = plt.scatter(x[~mask], x2[~mask], marker='^')
```

### chip

```python
#load the data  
import pandas as pd  
import numpy as np  
data = pd.read_csv('chip_test.csv')  
# data.head()

# 提取 test1 和 test2 列 这遭殃为需要的数据库
X = data[['test1', 'test2']]  
y = data['pass']  
# 计算新列  
X1_2 = X['test1'] ** 2  
X2_2 = X['test2'] ** 2  
X1_X2 = X['test1'] * X['test2']  
  
# 创建新的 DataFrame  
X_new = pd.DataFrame({'X1': X['test1'], 'X2': X['test2'], 'X1_2': X1_2, 'X2_2': X2_2, 'X1_X2': X1_X2})  
  
# 打印新的 DataFrame  
print(X_new)


#establish the model and train it  
from sklearn.linear_model import LogisticRegression  
LR2 = LogisticRegression()  
LR2.fit(X_new,y)

# 查看准确率
from sklearn.metrics import accuracy_score  
y2_predict = LR2.predict(X_new)  
accuracy2 = accuracy_score(y,y2_predict)  
print(accuracy2)


```


so how to use the trained model to predict new data:

```python
from sklearn.linear_model import LogisticRegression

# 假设您已经拟合了一个逻辑回归模型
model = LogisticRegression()
model.fit(X_train, y_train)

# 准备新数据
new_data = [[0.3, 0.7], [0.1, 0.9]]

# 使用模型预测新数据的类别
predictions = model.predict(new_data)

# 打印预测结果
print(predictions)
```

save the model and realod it next time

```python
from sklearn.externals import joblib

# 假设您已经拟合了一个模型
model = LogisticRegression()
model.fit(X, y)

# 将模型导出并保存到磁盘中
joblib.dump(model, 'model.joblib')

# 从磁盘中加载模型
model = joblib.load('model.joblib')

```

## 聚类问题

### K-means
均值聚类  无监督

```python
from sklearn.cluster import KMeans
KM = KMeans(n_clusters=3, random_state=0)
KM.fit(x)

-`n_clusters`：这个参数指定了要在数据中形成的簇的数量。在上面的示例中，`n_clusters=3` 意味着算法将尝试将数据分成 3 个簇。
-`random_state`：这个参数控制了随机数生成器的种子。它可以用于确保算法的结果是可重复的。在上面的示例中，`random_state=0` 意味着每次运行算法时都会使用相同的随机数种子，从而产生相同的结果
- 请注意，KMeans 算法是一种迭代算法，它从一组初始簇中心开始，并不断更新簇分配和簇中心，直到满足收敛条件。由于初始簇中心的选择是随机的，因此算法的结果可能会因随机数种子的不同而有所不同。通过设置 `random_state` 参数，您可以确保每次运行算法时都使用相同的随机数种子，从而获得可重复的结果。
```

get the centers of the model
```python
centers = KM.cluster_centers_
```

准确率计算 "Accuracy calculation"

```python 
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y, y_predict)
```

预测结果矫正 "Prediction result correction"

```python
y_cal = [ ]
for i in y_predict:
	if i == 0:
		y_cal.append(2)
	elif i == 1:
		y_cal.append(1)
	else:
		y_cal.append(0)
# 针对标签对不上的情况
```

以空间中k个点为中心，对最靠近它们的点归类

### KNN
近邻分类  有监督（已标记好的数据,必须告诉它分几类）

model train

```python
from sklearn.neighbors import KNeighborsClassifier
KNN = KNeighborsClassifier(n_neighbors=3)
KNN.fit(x,y)
```

### meanShift
均值漂移， 基于密度梯度上升方向聚类  使用向量

自动计算带宽（半径）"Automatic bandwidth (radius) calculation"
```python
from sklearn.cluster import MeanShift, estimate_bandwidth

bandwidth = estimate_bandwidth(x, n_samples=500)
```

建立模型并训练  build model and train

```python
ms = MeanShift(bandwidth=bandwidth)
ms.fit(x)
```

### MLP


max-pooling : 最大法池化
avg-pooling: 平均池化