# 爬虫

分类：
>通用爬虫
>聚焦爬虫
>增量爬虫

反爬机制：

>robots协议
User-Agent 请求载体的身份标识 
>


## requests模块

### 请求

#### get
```python
requests.get(url=url,params=param,headers=headers)

response = request.get(url)

response.text  #  文本数据
response.content # 二进制数据

获取二进制数据还可以用urllib.request.urlretrieve(url=url,filename='file_name'),但它不能进行UA伪装
```
#### post

```python
response = requests.post(url=url,data=data,headers=headers)
#获取响应数据:如果响应回来的数据为json，则可以直接调用响应对象的json方法获取json对象数据
json_data = response.json()
```


## 数据解析

### 正则

### bs4

#### 包安装：
```python
pip install bs4
```
#### bs4使用流程：
导入模块 --> 实例化bs对象--->解析数据

#### 实例化对象

实例化时可以传入文件句柄，也可以是字符串类型。并指定解析引擎
```python
soup = BeautifulSoup(open('本地文件'), 'lxml')
soup = BeautifulSoup('字符串类型或者字节类型', 'lxml')
```
#### 数据解析

标签定位： 返回值 一定时定位到的标签
获取标签
`soup.a` # 定位到第一个出现的a标签，返回的是单数
获取属性
` soup.a.attrs  获取a所有的属性和属性值，返回一个字典`
`soup.a.attrs['href']   获取href属性(soup.a['href']   也可简写为这种形式)`
获取内容
```py
soup.a.string # 只可将标签中直系的文本取出
soup.a.text  #  可将标签中所有的文本取出
soup.a.get_text()
```
find：找到第一个符合要求的标签
```py
 soup.find('a')  找到第一个符合要求的，返回的是单数
 soup.find('a', title="xxx")
 soup.find('a', alt="xxx")
 soup.find('a', class_="xxx")
 soup.find('a', id="xxx")
```
find_all：找到所有符合要求的标签，返回的是列表
```py
 soup.find_all('a')
 soup.find_all(['a','b']) 找到所有的a和b标签
 soup.find_all('a', limit=2)  限制前两个
```
选择器定位：select('选择器') 返回的也是一个列表
层级：> 表示 一个层级。 空格： 表示多个层级
```
soup.select('.song')
soup.select('.tang' > ul > li') 
```

取属性： tag['attrName'] 
根据选择器选择指定的内容

### xpath

#### 安装包
```py
pip install lxml
```
#### 实例化对象
```py
etree.parse('filepath') # 本地数据加载到etree
etree.HTML(page_text) #互联网上的数据加载到对象中
```

#### 数据解析


取文本:
```
from lxml import etree

/text() # 取直系的文本内容,列表只有一个元素
tree.xpath('//a[@id="feng"]/text()')[0]

//text() # 所有的文本内容 , 列表会有多个列表元素
tree.xpath('//div[2]//text()')
```

取属性
```py
/@attrname
tree.xpath('//a[@id="feng"]/@href')
```
循环中做局部解析一定要用./

标签定位：
最左侧的/: xpath表达式一定要从要根标签(/html)开始进行定位
非最左侧的/:表示一个层级
最左侧的//:从任意位置进行标签定位 (常用)
非最左侧的//:表示多个层级

//tagName # 定位到所有的tagname标签
tree.xpath('//div')
属性定位  //tagName[@attrName="value"]
tree.xpath('//div[@class="tang"]')
tree.xpath('//li[3]')
索引定位: //tagName[index], index索引是从1开始
模糊匹配: //div[contains(@class, 'ng')] //div[starts-with(@class, 'ta')]