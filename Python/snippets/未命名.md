
## 代码块(snippets)：
### 多app管理 （apps && extra_apps）
当项目中因为app较多而将所有app添加到apps包目录下时，通过下面的方法将路径添加进环境中
```python
import os
import sys

# Build paths inside the project like this: os.path.join(BASE_DIR, ...)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, BASE_DIR)
sys.path.insert(0, os.path.join(BASE_DIR, 'apps'))
sys.path.insert(0, os.path.join(BASE_DIR, 'extra_apps'))
```

### 文件上传


#### 页面
```html
<form id='mmm'>
<input type="text" name='user' id='f1'/>
<input type="file" name='avatar' id='f2'/>
<input type="checkbox" />
</form>
```

#### ajax
```javascript

var formData = new FormData();
formData.append('k1',$('#f1').val())
formData.append('k2',$('#f2')[0].files[0])

/*整个form作为表单append到FormData对象*/
// 注意 如果表单中有checkbox或者radio标签且未选中，则FormData不会构造到自己的数据中
var formData = new FormData($('#mmm')[0]);
$.ajax({
    url:'..',
    type:"post",
    data:formData,
    
    cache: false,
    contentType: false,
    processData: false,
    
    success:function(res){
        console.log(res)
    }
})
```

#### 文件上传按钮美化，实时预览

##### css部分
```css
<style>
    .file-view {
        height: 80px;
        width: 80px;
        padding: 2px;
        border: 1px dotted #dddddd;
        position: relative;
    }

    .file-view .view-file {
        position: absolute;
        width: 100%;
        height: 100%;
        opacity: 0;
        z-index: 1001
    }
    .file-view .view-img {
        height: 100%;
        width: 100%;
        border: 0;
        overflow: hidden;
    }
</style>
```

##### Html部分

```html
<div class="file-view">
<input class="view-file" type="file" name="img">
<img class="view-img" src="{% static 'web/images/default-image.png'%}">
</div>
```

##### js部分
```javascript
$(function () {
    bindChangeImageFile();
});
function bindChangeImageFile() {
    $('#areaImage').on('change', '.view-file', function () {
        var fileObject = $(this)[0].files[0];
        var file_url = window.URL.createObjectURL(fileObject);
        $(this).next().attr('src', file_url);
        // 赋值完重新加载
        $(this).next().load(function () {
            window.URL.revokeObjectURL(file_url);
    })
})
```


#### drf中文件上时重新选择文件
```py
from django.core.files.uploadedfile import InMemoryUploadedFile #这个是更改了
from django.db.models.fields.files import FieldFile #这个是没更改
```

### 自定义标签过,滤器

#### 在app中新建一个templatetags包

#### 创建文件
> 在settings中注册当前app
> 如：cus_tags.py 那么在页面中引用 为`{% load cus_tags %}`

#### 编写标签，过滤器

```python
from django import template
from django.utils.safestring import mark_safe

register = template.Library()   #register的名字是固定的,不可改变

@register.filter
def filter_multi(v1,v2):
    return  v1 * v2

@register.simple_tag  #和自定义filter类似，只不过接收更灵活的参数，没有个数限制。
def simple_tag_multi(v1,v2):
    return  v1 * v2

@register.simple_tag
def my_input(id,arg):
    result = "<input type='text' id='%s' class='%s' />" %(id,arg,)
    return mark_safe(result)
```

```python
from django import template

register = template.Library()

@register.inclusion_tag('result.html')  #将result.html里面的内容用下面函数的返回值渲染，然后作为一个组件一样，加载到使用这个函数的html文件里面
def show_results(n): #参数可以传多个进来
    n = 1 if n < 1 else int(n)
    data = ["第{}项".format(i) for i in range(1, n+1)]
    return {"data": data}#这里可以穿多个值，和render的感觉是一样的{'data1':data1,'data2':data2....}
```

####  页面中使用
` {% simple_tag_multi 1 2 %}`



### 请用两个队列来实现一个栈(给出伪代码即可)
```python
import queue
class Stack:
    def __init__(self):
        self.master_queue = queue.Queue()
        self.minor_queue = queue.Queue()

    def push(self, value):
        self.master_queue.put(value)

    def pop(self):
        if self.master_queue.qsize() == 0:
            return None

        while True:
            if self.master_queue.qsize() == 1:
                value = self.master_queue.get()
                break
            self.minor_queue.put(self.master_queue.get())
        self.master_queue, sefl.minor_queue = self.minor_queue,self.master_queue
        return value
```

### socket
wrap_socket 旧的接口不能用，改为使用context

```python
cert_file = str('')
key_file = str('')
context = ssl.SSLContext(ssl.ProTocol_SSLv23)
context.check_hostname = False
context.verify_mode = ssl.CERT_NONE
context.load_cert_chain(cert,key)
_socket = context.wrap_socket()
```

### datetime to timezone
```python
import pytz
from datetime import datetime
unware_time = datetime.strptime(time_str,'%Y-%d-%d %H:%M:%s')
unware_time.replace(tzinfo=pytz.UTC)
```

### 时间（time）

#### asctime

```python
time.asctime() // 'Fri Sep 15 14:46:37 2023' 
```

它不接受任何参数，也就是它只能返回上面样式的字符串，比较鸡肋

#### ctime

将一个指定的秒数转成上面的asctime 样式的字符串格式，如果没有指定秒数，默认使用time.time() 返回值。

```python
>>> time.ctime()
'Fri Sep 15 14:53:17 2023'
```
#### gmtime
将一个指定秒数转成结构化时间

```python
>>> time.gmtime()
time.struct_time(tm_year=2023, tm_mon=9, tm_mday=15, tm_hour=6, tm_min=54, tm_sec=44, tm_wday=4, tm_yday=258, tm_isdst=0)

- `tm_year`：年份，例如2023
- `tm_mon`：月份，范围从1（一月）到12（十二月）
- `tm_mday`：一个月中的第几天，范围从1到31
- `tm_hour`：小时，范围从0（午夜）到23
- `tm_min`：分钟，范围从0到59
- `tm_sec`：秒，范围从0到61（60和61用于闰秒）
- `tm_wday`：一周中的第几天，范围从0（星期一）到6（星期日）
- `tm_yday`：一年中的第几天，范围从1到366
- `tm_isdst`：夏令时标志，值为0表示标准时间，为1表示夏令时。如果信息不可用，则为-1
```

#### localtime
与上面的gmtime 一样，但是会转为本地时间，目前就发现小时显示不一样，对于gmtime 会显示6， 而localtime则显示14



### re模块

#### look around:

- look forward

```python

In [12]: txt = "i love python, i love regex"
# 后面是python的Love
In [13]: pattern = re.compile("love\s(?=python)")
# 所以这里只能匹配出第一个love, 因为第二个love后面接的regex
In [14]: pattern.search(txt)
Out[14]: <re.Match object; span=(2, 7), match='love '>
# 后面不是python的Love
In [15]: pattern = re.compile("love\s(?!python)")
# 通过索引可以看到，匹配的是第二个love, 因为第一个Love后面接的是python
In [16]: pattern.search(txt)
Out[16]: <re.Match object; span=(17, 22), match='love '>
# 后面既不能是python也不能是love
In [17]: pattern = re.compile("love\s(?!python|regex)")

In [18]: pattern.search(txt)
```

the word after "?=" or "?!" will not consuming characters. the first one `love\s(?=python)` means only match the word love which is followed by python.
if i change the "?=" to "?!" means not match, so the result is the "love" folled by regex

- look back/behind

```python
# 肯定型后视断言，这里的<= 可以理解为在当前位置回退几个字符，看是否能匹配上内部的模式
# 这里的内部的模式即pattern in the brackets, but remmber the pattern lenght is
# accurate, but not variable(a.*, a{3,4} is not allowed)
In [72]: text = "love regex or hate regex, can't ignore regex"

In [73]: pattern = re.compile("(?<=(love|hate)\s)regex")

In [74]: pattern.findall(text)
Out[74]: ['love', 'hate']

# negetive look back, which is oppoiste to the up one
In [94]: pattern = re.compile("(?<!love\s)regex")

In [95]: pattern.findall(text)
Out[95]: ['regex', 'regex']

# i don't known why this negetive lookbehind not work even if i change the 
# the inside mode to a or anything else.
In [96]: pattern = re.compile("(?<!(love|hate)\s)regex")
In [97]: pattern.findall(text)
Out[97]: ['']

```

the word after ?<= will only match the word  has hate or love before regex.  and ?<! not match. but there is sth confusing: when i use "love|hate" why it return "" ? 

### argparse
 argparse example
```python
#!/usr/bin/env python
# coding: utf-8 
# Create by Andy963 @2021-01-10 10:50:27


import argparse


def fib(n):
    a, b = 0, 1
    for i in range(n):
        a, b = b, a + b
    return a


def main():
    parser = argparse.ArgumentParser()
    group = parser.add_mutually_exclusive_group()
    group.add_argument("-v", "--verbose", action="store_true")
    group.add_argument("-q", "--quite", action="store_true")

    parser.add_argument("num", help="The fibonacci number you wish to calculate.", type=int)
    parser.add_argument('-o', "--output", help="Output result to a file", action="store_true")
    args = parser.parse_args()

    result = fib(args.num)
    if args.verbose:
        print("The " + str(args.num) + "th fib number is " + str(result))
    elif args.quite:
        print(result)
    else:
        print("fib(" + str(args.num) + ") =" + str(result))

    if args.output:
        f = open("fib.txt", "a")
        f.write(str(result) + "\n")


if __name__ == '__main__':
    main()
```

## 测试（unittest）

```python
import unittest

class MyTestCase(unittest.TestCase):
    def test_upper(self):
        self.assertEqual('andy'.upper(), 'ANDY')

    def test_is_upper(self):
        self.assertTrue('ANDY'.isupper())
        self.assertFalse('Andy'.isupper())

if __name__ == '__main__':
    unittest.main()
```

通过继承unittest.TestCase来实现一个测试用例，在这个类中，定义的以test开关的方法，测试框架将把它当作独立的测试来执行。

如果我们希望在测试前做一些准备工作，在测试之后做一些清理工作，我们就用到了fixtures(固定装置)，指的测试开始前的准备工作setUp和测试完成后的清理工作tearDown
#### 方法级别的fixtures

```python
class MyTestCase(unittest.TestCase):
    def setUp(self):
        pass

    def test_sth(self):
        pass

    def tearDown(self):
        pass
```

#### 类级别的fixtures

```python
class MyTestCase(unittest.TestCase):
    def setUpClass(self):
        pass

    def tearDownClass(self):
        pass
```
#### 模块级别的fixtures
```python
def setUpModule():
    pass

def tearDownModule():
    pass
```

### 跳过测试和预计失败
unittest 支持直接跳过或按条件跳过测试，也支持预计测试失败：

通过 skip 装饰器或 SkipTest 直接跳过测试
通过 skipIf 或 skipUnless 按条件跳过或不跳过测试
通过 expectedFailure 预计测试失败
```python
class MyTestCase(unittest.TestCase):

    @unittest.skip("直接跳过")
    def test_nothing(self):
        self.fail("shouldn't happen")

    @unittest.skipIf(mylib.__version__ < (1, 3),"满足条件跳过")
    def test_format(self):
        # Tests that work for only a certain version of the library.
        pass

    @unittest.skipUnless(sys.platform.startswith("win"), "满足条件不跳过")
    def test_windows_support(self):
        # windows specific testing code
        pass

    def test_maybe_skipped(self):
        if not external_resource_available():
            self.skipTest("跳过")
        # test code that depends on the external resource
        pass

    @unittest.expectedFailure
    def test_fail(self):
        self.assertEqual(1, 0, "这个目前是失败的")

```

### 子测试
用不同的参数来测试同一段逻辑，但又不希望被视作同一个测试。就可以使用子测试
示例中使用了 with self.subTest(i=i) 的方式定义子测试，这种情况下，即使单个子测试执行失败，也不会影响后续子测试的执行。这样，我们就能看到输出中有三个子测试不通过
```python
class NumbersTest(unittest.TestCase):

    def test_even(self):
        """
        Test that numbers between 0 and 5 are all even.
        """
        for i in range(0, 6):
            with self.subTest(i=i):
                self.assertEqual(i % 2, 0)

```

## 异步
### asyncio使用

我们先看下面的例子：

```python
import time
from datetime import datetime


def print_message_periodical(interval_seconds, message='keep alive'):
    while True:
        print(f'{datetime.now()} - {message}')
        start = time.time()
        end = start + interval_seconds
        while True:
            yield
            now = time.time()
            if now >= end:
                break


if __name__ == "__main__":
    a = print_message_periodical(3, 'three')
    b = print_message_periodical(10, 'ten')
    stack = [a, b]
    while True:
        for task in stack:
            next(task)
```
因为yield的存在，当print_message_periodical函数执行到这里时会中断，返回yield的值（yield类似return但不会结束函数)， 这样再次执行next时，就会执行另一个task，达到了切换的目的。中断，切换即异步的核心。

那么asyncIo是怎么做的呢？
```python
import asyncio
import time
from math import sqrt
from datetime import datetime

async def print_message_periodical(interval_seconds, message='keep alive'): # p定义函数时使用async
    while True:
        print(f'{datetime.now()} - {message}')
        start = time.time()
        end = start + interval_seconds
        while True:
            await asyncio.sleep(0) # 需要中断的地方使用await
            now = time.time()
            if now >= end:
                break

if __name__ == "__main__":
    scheduler = asyncio.get_event_loop() # 获取 event_loop对象
    scheduler.create_task(
        print_message_periodical(3, 'three')
    )
    scheduler.create_task(
        print_message_periodical(10, 'ten')
    )
    scheduler.run_forever()
```

### 事件循环

伪代码：
```
任务列表 = [任务1，任务2，任务3]

while True:
    可执行任务列表，已完成任务列表 = 去任务列表中检查所有任务，将可执行/已完成的返回

    for 就绪任务 in 可执行任务列表：
        执行已经就绪任务

    for 已经完成任务 in 已经完成任务列表
        在任务列表中移除已经完成任务

    如果 任务列表 中的任务都已经完成  终止循环
```
import asyncio
#去生成或者获取一个事件循环
loop = asyncio.get_evnet_loop()

#将任务添加到 '任务列表'
loop.run_until_complete(任务)

### 使用流程
- 定义协程函数
- 得到协程对象
- 执行

```python
import asyncio

async def func():  # 使用async def 来定义协程函数
    print('来了，来了')

result = func()  # 返回是一个协程对象

# 执行
loop = asyncio.get_event_loop()
loop.run_until_complete(result)

# asyncio.run(result) python3.7才有
```



### await

**示例1**
```python
await + 可等待对象 (协程对象，Future对象,Task对象 -> IO等待)

import asyncio

async def func():
    print('hello')
    result = await asyncio.sleep(2)
    print('finish', result)

asyncio.run(func())

执行流程： 
func添加到列表中后，先执行print, 此时遇到IO,如果有其他任务，就会切换到其他任务，当其他任务完成或者也遇到IO,切换回来，如果有返回值，交给result,再执行
print语句
```

**示例2**
```python
import asyncio

async def others():
    print('start')
    await asyncio.sleep(2)
    print('end')
    return '返回值'

async def func():
    print('执行协程函数内部代码')
    #遇到IO操作，挂起当前协程(任务）等IO操作完成之后再继续往下执行
    # 当前协程挂起时，事件循环就会去执行其他协程任务

    result = await others()

    print('IO操作完成，结果为：',result)
# asyncio.run(func())
loop = asyncio.get_event_loop()
loop.run_until_complete(func())
```
**执行结果**
执行协程函数内部代码
start
end
IO操作完成，结果为： 返回值

**示例3**
多个await对象
```python
import asyncio

async def others():
    print('start')
    await asyncio.sleep(2)
    print('end')
    return '返回值'

async def func():
    print('执行协程函数内部代码')
    #遇到IO操作，挂起当前协程(任务）等IO操作完成之后再继续往下执行
    # 当前协程挂起时，事件循环就会去执行其他协程任务

    result = await others()

    print('IO操作完成，结果为：',result)

    result1 = await others()

    print('IO操作完成，结果为：',result1)
# asyncio.run(func())
loop = asyncio.get_event_loop()
loop.run_until_complete(func())

```

### Task对象
task对象在事件循环中添加多个任务，用于并发调度协程，通过asyncio.create_task(协程对象)的方式创建task对象，这样可以让协程加入事件循环中等待被调度执行，除了使用asyncio.create_task(),函数以外，还可以用低层级的loop.create_task(),ensure_future()函数，不建议手动实例化Task对象。
**示例1**
```python
import asyncio

async def fun():
    print('start')
    await asyncio.sleep(2)
    print('end')
    return '返回值'

async def main():
    print('执行协程函数内部代码')
    #遇到IO操作，挂起当前协程(任务）等IO操作完成之后再继续往下执行
    # 当前协程挂起时，事件循环就会去执行其他协程任务

    # task1 = asyncio.create_task(fun())
    # task2 = asyncio.create_task(fun())
    task1 = asyncio.ensure_future(fun())
    task2 = asyncio.ensure_future(fun())

    print('main finish')

    result1 = await task1
    result2 = await task2

    print('IO操作完成，结果为：',result1,result2)
# asyncio.run(main())
loop = asyncio.get_event_loop()
loop.run_until_complete(main())

```
**结果**
执行协程函数内部代码
main finish
start
start
end
end
IO操作完成，结果为： 返回值 返回值

**示例2**
```python
import asyncio

async def fun():
    print('start')
    await asyncio.sleep(2)
    print('end')
    return '返回值'

async def main():
    print('执行协程函数内部代码')
    #遇到IO操作，挂起当前协程(任务）等IO操作完成之后再继续往下执行
    # 当前协程挂起时，事件循环就会去执行其他协程任务

    # task1 = asyncio.create_task(fun()) create_task可以添加name参数指定名字
    # task2 = asyncio.create_task(fun())
    task1 = asyncio.ensure_future(fun())
    task2 = asyncio.ensure_future(fun())

    task_list = [task1,task2] # 定义一个task对象列表

    print('main finish')

    done,pending = await asyncio.wait(task_list,timeout=2) #timeout参数为可选，如果超出时间那么就没执行完，此时done为空，pending为未执行完的对象


    print('IO操作完成，结果为：',done)
# asyncio.run(main())
loop = asyncio.get_event_loop()
loop.run_until_complete(main())
```

**结果**
执行协程函数内部代码
main finish
start
start
IO操作完成，结果为： set()
end

可以看到done为一个集合。

**示例3**
```python
import asyncio

async def fun():
    print('start')
    await asyncio.sleep(2)
    print('end')
    return '返回值'

task_list = [fun(),fun()] # 定义一个task对象列表

done,pending = asyncio.run(asyncio.wait(task_list,timeout=2))
print(done)
```

### future对象
Task继承Future,Task对象内部await 结果的处理基于Future对象来的
**示例1**
```python
import asyncio

async def main():
    # 获取当前事件循环
    loop = asyncio.get_running_loop()

    # 创建一个任务（future对象） 这个任务什么也不干
    fut = loop.create_future()

    # 等待任务最终结果（Future对象）没有结果会一直等下去
    await fut

asyncio.run(main())
```

**示例2**
```python
import asyncio

async def set_after(fut):
    await asyncio.sleep(2)
    fut.set_result('0')

async def main():
    # 获取当前事件循环
    loop = asyncio.get_running_loop()

    # 创建一个任务（future对象） 没绑定任何行为，则这个任务永远不知道什么时候结束 
    fut = loop.create_future()

    # 创建一个任务（Task对象）绑定了set after函数，函数内部在2s后给fut赋值
    # 即手动设置future任务的结果，那么fut就结束了
    await loop.create_task(set_after(fut))
    data = await fut
    
asyncio.run(main())
```

### concurrent.futures.Future对象

```python
import time
from concurrent.futures import future 
from concurrent.futures.thread import ThreadPoolExecutor
from concurrent.futures.process import processPoolExecutor


def func(value):
    time.sleep(1)
    print(value)
    return
pool = ThreadPoolExecutor(max_workers=5)

# pool = processPoolExecutor(max_workers=5)

for i in range(10):
    fut = pool.submit(func,i)
    print(fut)
    
```
线程池一次只能创建5个连接，但实际它创建了10个，后面的一个只是在等待前面的执行完成。
可能会存在交叉使用的情况：如异步编程+mysql(不支持异步）这时就可能使用Concurrent.futures

```python
import time
from concurrent.futures import future 
from concurrent.futures.thread import ThreadPoolExecutor
from concurrent.futures.process import processPoolExecutor


def func1(value):
    time.sleep(1)
    print(value)
    return


async def main():
    loop = asyncio.get_runing_loop()

    # run in the deafult executor(ThreadPoolExecutor)
    # 第一步先调用ThreadPoolExecutor的submit方法去线程池中申请一个线程 执行func1函数 
    # 并返回一个concurrent.futures.Future对象
    # 第二步 调用asyncio.wrap_future将concurrent.futures.Future对象包装成asyncio.Future对象
    # 因为concurrent.futures.Future对象不支持await语法，所以需要包装为asyncio.Future对象才能使用
    fut = loop.run_in_executor(None,func1)
    result = await fut
    print('default thread pool', result)

    # 2 run in custom thread pool
    with concurrent.futures.ThreadPoolExecutor() as pool:
        result = await loop.run_in_executor(pool, func1)
        print('custom thread pool',result)
    # 3 run in a custom process pool
    with concurrent.futures.processPoolExecutor() as pool:
        result = await loop.run_in_executor(pool, func1)
        print('custom process pool',result)

asyncio.run(main())
```

**实例**
```python
import asyncio
import requests

async def download_images(url):
    # 发送网络请求，下载图片，遇到网络IO,自动切换到其它任务
    print('开始下载', url)
    loop = asyncio.get_event_loop()

    # requests 默认不支持异步操作，所以使用线程池来配合实现
    future = loop.run_in_executor(None, requests.get, url)

    response = await future
    print('下载完成')
    file_name = url.rsplit('-')[-1]

    with open(file_name, mode='wb') as file_obj:
        file_obj.write(response.content)


if __name__ == '__main__':
    url_list = []
    tasks = [download_images(url) for url in url_list]
    loop = asyncio.get_event_loop()
    loop.run_until_complete(asyncio.wait(tasks))
```

### 异步迭代器
```python
import asyncio


class Reader:
    def __init__(self):
        self.count = 0

    async def read_count(self):
        # await asyncio.sleep(1)
        self.count += 1
        if self.count == 100:
            return None
        return self.count

    def __aiter__(self):
        return self

    async def __anext__(self):
        val = await self.read_count()
        if val == None:
            raise StopAsyncIteration
        return val


async def func():
    obj = Reader()
    # async for 必须写在一个协程函数中
    async for item in obj:
        print(item)


asyncio.run(func())

```

### 异步上下文管理器
```python
import asyncio


class AsyncContextManager:
    def __int__(self):
        self.conn = conn

    async def do_something(self):
        # 异步操作
        return

    async def __aenter__(self):
        # 异步
        self.conn = await asyncio.sleep(1)
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        # 异步关闭
        await asyncio.sleep(1)


obj = AsyncContextManager()


async def func():
    # async with 必须放在协程函数中
    async with obj as f:
        result = await f.do_something()
        pass
```

### 异步redis
pip install aioredis
```python
import asyncio
import aioredis

async def execute(address,password):
    print('开始执行',address)
    # 网络io操作，创建redis连接
    redis=await aioredis.create_redis(address,password=password)
    # 网络IO操作，在redis中设置哈希值
    await = redis.hmset_dict('car',key=1,key2=2,key3=3)
    # 网络IO操作，去redis中获取值
    result = await redis.hgetall('car',encoding='utf-8')

    print(result)
    # 网络IO操作，关闭redis连接
    redis.close()
    print('结束')

asyncio.run(func)
```

### 异步mysql
```python
import asyncio
import aiomysql

async def execute():  
    conn = await aiomysql.connct(host='127.0.0.1',port=3306,usr='root',password='123',db='mysql')

    # 网络IO 创建cursor
    cur = await conn.cursor
    # 网络IO 执行sql
    await cur.execute('Select * from user')
    # 网络IO 获取结果 
    result = await cur.fetchall()
    print(result)
    # 网络IO 关闭连接
    await cur.close()
    conn.close()

asyncio.run(execute)

```

**多个连接**
```python
import asyncio
import aiomysql

async def execute():  
    conn = await aiomysql.connct(host='127.0.0.1',port=3306,usr='root',password='123',db='mysql')

    # 网络IO 创建cursor
    cur = await conn.cursor
    # 网络IO 执行sql
    await cur.execute('Select * from user')
    # 网络IO 获取结果 
    result = await cur.fetchall()
    print(result)
    # 网络IO 关闭连接
    await cur.close()
    conn.close()
task_list = [
 execute('1.1.1.1','password1'),
 execute('1.2.3.4','password2')
]
asyncio.run(asyncio.wait(task_list))

```

### FastAPi
```shell
pip install fastapi
pip install uvicorn
```

**示例**
```python
import asyncio

import uvicorn
from fastapi import FastAPI 

app = FastAPI()

REDIS_POOL = aioredis.ConnectionsPool('redis://ip:port',password='password',minsize=1,maxsize=10)

@app.get('/')
def index():
    # 普通接口
    return {"msg":'hello world'}

async def read():
    # 异步接口
    print('请求来了')
    await asyncio.sleep(3)
    # 连接
    conn = await REDIS_POOL.acquire()
    redis = redis(conn)

    # 设置值
    await redis.hmset_dict('car',key1=1,key2=2)

    # 取值
    result = await redis.hgetall('car',encoding='utf-8')

    # REDIS_POOL.release(conn)
    return result

if __name__ == '__main__':
    uvicorn.run('code:app',host='127.0.0.1',port=5000,log_level='info')

```

### 爬虫
```shell
pip install aiohttp
```

```python
import aiohttp
import asyncio


async def fetch(session,url):
    print('发送请求',url)
    async with session.get(url, verify_ssl=False) as response:
        text = await response.text
        print('得到结果',url,len(text))

async def main():
    async with aiohttp.ClientSession() as session:
        url_list = [
        'https://python.org',
        'https://www.baidu.com'
        ]
        tasks = [asyncio.create_task(fetch(session,url) for url in url_list)]

        await asyncio.wait(tasks)

if __name__ == '__main__':
    asyncio.run(main())
```

### 同步与阻塞的关系

#### 状态
在程序运行的过程中，由于被操作系统的调度算法控制，程序会进入几个状态：就绪，运行和阻塞。

（1）就绪(Ready)状态
当进程已分配到除CPU以外的所有必要的资源，只要获得处理机便可立即执行，这时的进程状态称为就绪状态。
（2）执行/运行（Running）状态当进程已获得处理机，其程序正在处理机上执行，此时的进程状态称为执行状态。
（3）阻塞(Blocked)状态正在执行的进程，由于等待某个事件发生而无法执行时，便放弃处理机而处于阻塞状态。引起进程阻塞的事件可有多种，例如，等待I/O完成、申请缓冲区不能满足、等待信件(信号)等。

#### 同步与异步
所谓同步就是一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列其实就是一个程序结束才执行另外一个程序，串行的，不一定两个程序就有依赖关系。

所谓异步是不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。至于被依赖的任务最终是否真正完成，依赖它的任务无法确定，所以它是不可靠的任务序列。

举例
> 比如我们去楼下的老家肉饼吃饭，饭点好了，取餐的时候发生了一些同步异步的事情。同步：我们都站在队里等着取餐，前面有个人点了一份肉饼，后厨做了很久，但是由于同步机制，我们   还是要站在队里等着前面那个人的肉饼做好取走，我们才往前走一步。

> 异步：我们点完餐之后，点餐员给了我们一个取餐号码，跟你说，你不用在这里排队等着，去找个地方坐着玩手机去吧，等饭做好了，我叫你。这种机制(等待别人通知)就是异步等待消息通知。在异步消息处理中，等待消息通知者(在这个例子中等着取餐的你)往往注册一个回调机制，在所等待的事件被触发时由触发机制(点餐员)通过某种机制(喊号，‘250号你的包子好了‘)找到等待该事件的人。
> 
#### 阻塞和非阻塞

阻塞和非阻塞这两个概念与程序（线程）等待消息通知(无所谓同步或者异步)时的状态有关。也就是说阻塞与非阻塞主要是程序（线程）等待消息通知时的状态角度来说的

**阻塞和非阻塞举例**

> 继续上面的那个例子，不论是排队还是使用号码等待通知，如果在这个等待的过程中，等待者除了等待消息通知之外不能做其它的事情，那么该机制就是阻塞的，表现在程序中,也就是该程序一直阻塞在该函数调用处不能继续往下执行。相反，有的人喜欢在等待取餐的时候一边打游戏一边等待，这样的状态就是非阻塞的，因为他(等待者)没有阻塞在这个消息通知上，而是一边做自己的事情一边等待。阻塞的方法：input、time.sleep，socket中的recv、accept等等。

#### 比较
**同步阻塞形式**
效率最低。拿上面的例子来说，就是你专心排队，什么别的事都不做。

**异步阻塞形式**
如果在排队取餐的人`采用的是异步的方式去等待消息被触发（通知）`，也就是领了一张小纸条，假如在这段时间里他不能做其它的事情，就在那坐着等着，不能玩游戏等，那么很显然，这个人被阻塞在了这个等待的操作上面；
**异步操作是可以被阻塞住的，只不过它不是在处理消息时阻塞，而是在等待消息通知时被阻塞。**

**同步非阻塞形式**
实际上是效率低下的。
想象一下你一边打着电话一边还需要抬头看到底队伍排到你了没有，如果把打电话和观察排队的位置看成是程序的两个操作的话，`这个程序需要在这两种不同的行为之间来回的切换`，效率可想而知是低下的。

**异步非阻塞形式**
效率更高，
因为打电话是你(等待者)的事情，而通知你则是柜台(消息触发机制)的事情，`程序没有在两种不同的操作中来回切换`。
比如说，这个人突然发觉自己烟瘾犯了，需要出去抽根烟，于是他告诉点餐员说，排到我这个号码的时候麻烦到外面通知我一下，那么他就没有被阻塞在这个等待的操作上面，自然这个就是异步+非阻塞的方式了。

很多人会把同步和阻塞混淆，是`因为很多时候同步操作会以阻塞的形式表现出来`，同样的，很多人也会把异步和非阻塞混淆，`因为异步操作一般都不会在真正的IO操作处被阻塞`。


#### 生产者和消费者模型

在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序的整体处理数据的速度。

**为什么要使用生产者和消费者模式**
在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这个问题于是引入了生产者和消费者模式。

**什么是生产者消费者模式**

​	生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力，并且我可以根据生产速度和消费速度来均衡一下多少个生产者可以为多少个消费者提供足够的服务，就可以开多进程等等，而这些进程都是到阻塞队列或者说是缓冲区中去获取或者添加数据。


**通过队列实现一个生产者和消费者模型**

```python
import time,random,os
from multiprocessing import Process,Queue

def consumer(q):
    while True:
        res=q.get()
        time.sleep(random.randint(1,3))
        print('\033[45m%s 吃 %s\033[0m' %(os.getpid(),res))

def producer(q):
    for i in range(10):
        time.sleep(random.randint(1,3))
        res='包子%s' %i
        q.put(res)
        print('\033[44m%s 生产了 %s\033[0m' %(os.getpid(),res))

if __name__ == '__main__':
    q=Queue()
    #生产者们:即厨师们
    p1=Process(target=producer,args=(q,))

    #消费者们:即吃货们
    c1=Process(target=consumer,args=(q,))

    #开始
    p1.start()
    c1.start()
    print('主')
```

上述模型解释
```
#生产者消费者模型总结

    #程序中有两类角色
        一类负责生产数据（生产者）
        一类负责处理数据（消费者）
        
    #引入生产者消费者模型为了解决的问题是：
        平衡生产者与消费者之间的工作能力，从而提高程序整体处理数据的速度
        
    #如何实现：
        生产者<-->队列<——>消费者
    #生产者消费者模型实现类程序的解耦和
    
缓冲和解耦
```



## 上下文管理器

### 一般的上下文管理器
通常情况下，上下文管理器是这样的
```python
class MyResource:
    def __enter__(self):
        print('connect to resource')
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        print('close resource connection')

    def query(self):
        print('query data')

with MyResource() as r:
    r.query()
```

它的执行流程是：enter,返回实例对象，即我们的r,然后执行r.query(), 最后退出 执行exit方法。用一种函数表示就是这种样的：(显然这是行不通的)

```python
def make_myresource():
    print('connect to resource')
    return MyResource()# 跳出去执行查找方法
    print('close resource connection')

with make_myresource() as r
    r.query()
```

原因是return会中止程序，不再执行后面的代码，那么，如果我们使用的是yield呢？因为yield会保存状态，并且再下一次执行时接着从上一次执行的地方继续执行，我们改造一下：

### contextmanager

```python
# encoding:utf-8
from contextlib import contextmanager


class MyResource:
    def query(self):
        print('query data')


@contextmanager
def make_myresource():
    print('connect to resource')
    yield MyResource()
    print('close resource connection')
    
with make_myresource() as r:
    r.query()
```

执行

```python
connect to resource
query data
close resource connection
```

### 应用

#### 改造print
假设我们在打印一本书名是，想自动给书名前后加上书名号《》,类似这样的，即输出的结果是：《活着》
```python
with book_mark():
    print("《")
    print("活着")
    print("》")
```
我们先用一般的上下文管理的方式实现：
```python
class BookMark:
    def __enter__(self):
        print("《", end='')

    def __exit__(self, exc_type, exc_val, exc_tb):
        print("》", end='')

with BookMark():
    print('活着',end='')
```

现在我们来改造它：

```python
from contextlib import contextmanager
@contextmanager
def make_mark():
    print("《",end='')
    yield
    print("》",end='')

with make_mark():
    print('活着', end='')
```

简单总结一下：我们要编写的这个需要contextmanager装饰的函数中yield之前会执行enter中的操作，而yield之后 则是执行exit中的操作。而真正的动作则是在with语句中执行即可。

伪代码：
```python
@contextmanager
def func():
    enter (进入时的操作)
    yield  （跳出，执行我们的核心动作）
    exit (退出前的操作）

with func as f:
     核心动作
```

#### 数据库提交
下面看更实际的例子：在数据据库提交数据使用事务来保证它原子性操作，要怎么改造呢
未修改前：
```python
class DB:  
    def __init__(self, url="sqlite:///db.sqlite3"):  
        self.engine = create_engine(  
            url=url,  
            connect_args={"check_same_thread": False},  
            pool_size=10,  
            max_overflow=20,  
            pool_recycle=3600,  # 连接在连接池中的回收时间  
            pool_pre_ping=True,  # 在使用前检查连接是否有效  
        )  
        self.Session = scoped_session(sessionmaker(bind=self.engine))  
  
    @contextmanager  
    def get_session(self, method_name=None):  # autocommit=True  
        session = self.Session()  
        try:  
            yield session  # enter 处理的逻辑
            session.commit()  # exit 时处理的逻辑， 提交事务  
        except Exception as e:  
            session.rollback()  # 回滚事务  
            if method_name:  
                db_logger.error(f"Error in method {method_name}: {e}", exc_info=True)  
            raise e  
        finally:  
            session.close()  # 关闭会话
```


总结：
在我们定定义的需要contextmanager装饰的函数中我们只需要写，前戏和事后回味两部分内容。这两部分内容用yield分隔开。
而在我们调用with语句中则是执行真正的战斗部分。




